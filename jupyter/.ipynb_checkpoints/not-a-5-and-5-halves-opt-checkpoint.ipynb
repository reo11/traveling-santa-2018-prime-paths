{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "This kernel is based on [my previous kernel](https://www.kaggle.com/kostyaatarik/not-a-3-and-3-halves-opt) and while it shares the same idea of permutating the chunks of the path it expands it to fives of points and handles permutations much faster by moving the code that finds the best permutation of chunks to numba which is a great tool to squeeze everything you can from python.\n",
    "\n",
    "As an initial path to start optimization from I'll use the output from [my another kernel](https://www.kaggle.com/kostyaatarik/shame-on-me)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "Import all that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "4080f80d30b6e4702d2aac7c19e73d5e690574a3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "from sympy import isprime, primerange\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import KDTree\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import combinations, permutations\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc08acedd4b79e21759da2d92d01021659baa302"
   },
   "source": [
    "Read input data and define some arrays that we'll need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "d5b03d9b02ebc2f734c1cbfa77bdcbbb7dda9730"
   },
   "outputs": [],
   "source": [
    "cities = pd.read_csv('../input/cities.csv', index_col=['CityId'])\n",
    "XY = np.stack((cities.X.astype(np.float32), cities.Y.astype(np.float32)), axis=1)\n",
    "is_not_prime = np.array([0 if isprime(i) else 1 for i in cities.index], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b64627e6cbaffffc873eb9302e0087136ec85a1"
   },
   "source": [
    "Define fast scoring functions using numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c678bfe47a584d041019dafd02bf48d44622cc09"
   },
   "outputs": [],
   "source": [
    "@numba.jit('f8(i8, i8, i8)', nopython=True, parallel=False)\n",
    "def cities_distance(offset, id_from, id_to):\n",
    "    xy_from, xy_to = XY[id_from], XY[id_to]\n",
    "    dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n",
    "    distance = sqrt(dx * dx + dy * dy)\n",
    "    if offset % 10 == 9 and is_not_prime[id_from]:\n",
    "        return 1.1 * distance\n",
    "    return distance\n",
    "\n",
    "\n",
    "@numba.jit('f8(i4, i8[:])', nopython=True, parallel=False)\n",
    "def score_chunk(offset, chunk):\n",
    "    pure_distance, penalty = 0.0, 0.0\n",
    "    penalty_modulo = 9 - offset % 10\n",
    "    for path_index in numba.prange(chunk.shape[0] - 1):\n",
    "        id_from, id_to = chunk[path_index], chunk[path_index+1]\n",
    "        xy_from, xy_to = XY[id_from], XY[id_to]\n",
    "        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n",
    "        distance = sqrt(dx * dx + dy * dy)\n",
    "        pure_distance += distance\n",
    "        if path_index % 10 == penalty_modulo and is_not_prime[id_from]:\n",
    "            penalty += distance\n",
    "    return pure_distance + 0.1 * penalty\n",
    "\n",
    "\n",
    "@numba.jit('f8(i8[:])', nopython=True, parallel=False)\n",
    "def score_path(path):\n",
    "    return score_chunk(0, path)\n",
    "\n",
    "\n",
    "@numba.jit\n",
    "def chunk_scores(chunk):\n",
    "    scores = np.zeros(10)\n",
    "    pure_distance = 0\n",
    "    for i in numba.prange(chunk.shape[0] - 1):\n",
    "        id_from, id_to = chunk[i], chunk[i+1]\n",
    "        xy_from, xy_to = XY[id_from], XY[id_to]\n",
    "        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n",
    "        distance = sqrt(dx * dx + dy * dy)\n",
    "        pure_distance += distance\n",
    "        if is_not_prime[id_from]:\n",
    "            scores[9-i%10] += distance\n",
    "    scores *= 0.1\n",
    "    scores += pure_distance\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b2622874752149ec22bd669219b0540c2a86d56"
   },
   "source": [
    "The part below is different from my previous kernel. This is how we'll handle permutations in numba.\n",
    "\n",
    "Instead of passing list of chunks of different sizes to the function 'score_compound_chunk' we'll pass just the lists of their first and last elements and their lenghts. By calling this function from the function 'best_score_permutation_index' the index of the best permutation will be found in numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ae83ba78b4209885a6b8425e40bccb555fe9fa6f"
   },
   "outputs": [],
   "source": [
    "@numba.jit('f8(i8, i8, i8[:], i8[:], i8[:], i8, f8[:,:], i8[:])', nopython=True, parallel=False)\n",
    "def score_compound_chunk(offset, head, firsts, lasts, lens, tail, scores, indexes):\n",
    "    score = 0.0\n",
    "    last_city_id = head\n",
    "    for i in numba.prange(len(indexes)):\n",
    "        index = indexes[i]\n",
    "        first, last, chunk_len = firsts[index], lasts[index], lens[index]\n",
    "        score += cities_distance(offset, last_city_id, first)\n",
    "        score += scores[index, (offset + 1) % 10]\n",
    "        last_city_id = last\n",
    "        offset += chunk_len\n",
    "    return score + cities_distance(offset, last_city_id, tail)\n",
    "\n",
    "\n",
    "@numba.jit('i8(i8, i8, i8[:], i8[:], i8[:], i8, f8[:,:], i8[:,:], f8)', nopython=True, parallel=False)\n",
    "def best_score_permutation_index(offset, head, firsts, lasts, lens, tail, scores, indexes, best_score):\n",
    "    best_index = -1\n",
    "    for i in numba.prange(len(indexes)):\n",
    "        score = score_compound_chunk(offset, head, firsts, lasts, lens, tail, scores, indexes[i])\n",
    "        if score < best_score:\n",
    "            best_index, best_score = i, score\n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "190b0273a4291ad1985bee71aa5a41611adfbe16"
   },
   "source": [
    "Precompute close cities fives using KDTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "96b82655133cda1be8b882ea0ab64ec96939e33e"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IntProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\Kaggle\\lib\\site-packages\\tqdm\\_tqdm_notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIntProgress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# No total? Show info style bar with no progress tqdm status\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IntProgress' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-753b5b549a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneibs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mXY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcomb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneibs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Kaggle\\lib\\site-packages\\tqdm\\__init__.py\u001b[0m in \u001b[0;36mtqdm_notebook\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;34m\"\"\"See tqdm._tqdm_notebook.tqdm_notebook for full documentation\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_tqdm_notebook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_tqdm_notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_tqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Kaggle\\lib\\site-packages\\tqdm\\_tqdm_notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;31m# Replace with IPython progress bar display (with correct total)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         self.sp = self.status_printer(\n\u001b[1;32m--> 212\u001b[1;33m             self.fp, self.total, self.desc, self.ncols)\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# trick to place description before the bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Kaggle\\lib\\site-packages\\tqdm\\_tqdm_notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;31m# #187 #451 #558\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             raise ImportError(\n\u001b[1;32m--> 111\u001b[1;33m                 \u001b[1;34m\"IntProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m                 \u001b[1;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[1;31mImportError\u001b[0m: IntProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "kdt = KDTree(XY)\n",
    "\n",
    "fives = set()\n",
    "for i in tqdm(cities.index):\n",
    "    dists, neibs = kdt.query([XY[i]], 9)\n",
    "    for comb in combinations(neibs[0], 5):\n",
    "        if all(comb):\n",
    "            fives.add(tuple(sorted(comb)))\n",
    "    neibs = kdt.query_radius([XY[i]], 10, count_only=False, return_distance=False)\n",
    "    for comb in combinations(neibs[0], 5):\n",
    "        if all(comb):\n",
    "            fives.add(tuple(sorted(comb)))\n",
    "            \n",
    "print(f'{len(fives)} cities fives are selected.')\n",
    "\n",
    "# sort fives by distance\n",
    "@numba.jit('f8(i8[:])', nopython=True, parallel=False)\n",
    "def sum_distance(ids):\n",
    "    res = 0\n",
    "    for i in numba.prange(len(ids)):\n",
    "        for j in numba.prange(i + 1, len(ids)):\n",
    "            res += cities_distance(0, ids[i], ids[j])\n",
    "    return res\n",
    "\n",
    "fives = np.array(list(fives))\n",
    "distances = np.array(list(map(sum_distance, tqdm(fives))))\n",
    "order = distances.argsort()\n",
    "fives = fives[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6d155718a87c60380400af6a7516af256ad62ce"
   },
   "source": [
    "Load the initial path to start optimization from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7260b66eeec537d44d341888224ad3fd8823407"
   },
   "outputs": [],
   "source": [
    "path = np.array(pd.read_csv('../input/submission.csv').Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50e3d803ef50707fa8b522044cad69ddc22f1b09"
   },
   "source": [
    "Use the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1734f1368fb55ad8efb4380f6c7265d481947897"
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def indexes_permutations(n):\n",
    "    return np.array(list(map(list, permutations(range(n)))))\n",
    "\n",
    "\n",
    "path_index = np.argsort(path[:-1])\n",
    "print(f'Total score is {score_path(path):.2f}.')\n",
    "for _ in range(2):\n",
    "    for ids in tqdm(fives[:2 * 10**6]):\n",
    "        i1, i2, i3, i4, i5 = np.sort(path_index[ids])\n",
    "        head, tail = path[i1-1], path[i5+1]\n",
    "        chunks = [path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3],\n",
    "                  path[i3:i3+1], path[i3+1:i4], path[i4:i4+1], path[i4+1:i5], path[i5:i5+1]]\n",
    "        chunks = [chunk for chunk in chunks if len(chunk)]\n",
    "        scores = np.array([chunk_scores(chunk) for chunk in chunks])\n",
    "        lens = np.array([len(chunk) for chunk in chunks])\n",
    "        firsts = np.array([chunk[0] for chunk in chunks])\n",
    "        lasts = np.array([chunk[-1] for chunk in chunks])\n",
    "        best_score = score_compound_chunk(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks))[0])\n",
    "        index = best_score_permutation_index(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks)), best_score)\n",
    "        if index > 0:\n",
    "            perm = [chunks[i] for i in indexes_permutations(len(chunks))[index]]\n",
    "            path[i1-1:i5+2] = np.concatenate([[head], np.concatenate(perm), [tail]])\n",
    "            path_index = np.argsort(path[:-1])\n",
    "            print(f'New total score is {score_path(path):.3f}. Permutating path at indexes {i1}, {i2}, {i3}, {i4}, {i5}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b66ddc715194f2e335eeb7f71d2d758b37b277e9"
   },
   "source": [
    "Save the result path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c840af354f2152858c81a62f16219d679f714ca1"
   },
   "outputs": [],
   "source": [
    "def make_submission(name, path):\n",
    "    pd.DataFrame({'Path': path}).to_csv(f'{name}.csv', index=False)\n",
    "\n",
    "\n",
    "make_submission(score_path(path), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
